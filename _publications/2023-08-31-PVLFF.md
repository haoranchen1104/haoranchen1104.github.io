---
title: "Panoptic Vision-Language Feature Fields"
header:
    teaser: /images/publication/PVLFF/teaser.png
collection: publications
permalink: /publication/PVLFF
excerpt: 'In this paper, we proposed a open-vocabulary panoptic system based on neural fields for scene understanding. Our method implicitly reconstructs the scene geometry from 2D images and simultaneously gains panoptic informaiton from 2D proposals computed by off-the-shelf 2D networks.'
date: 2023-08-31
venue: 'IEEE RA-L'
paperurl: 'https://arxiv.org/abs/2309.05448'
projecturl: 'https://ethz-asl.github.io/pvlff/'
videourl: 'https://youtu.be/mZoujkg_axE?si=AExcpTc15Pfo5gE2'
citation: 'Haoran Chen, Kenneth Blomqvist, Francesco Milano and Roland Siegwart. &quot;Panoptic Vision-Language Feature Fields.&quot; <i>IEEE Robotics and Automation Letters</i>. 2024'
codeurl: 'https://github.com/ethz-asl/autolabel'
---

<font size="1"><i>This project was undertaken at <a href="https://asl.ethz.ch/">Autonomous Systems Lab</a>, ETH ZÃ¼rich.</i></font>

> In this paper, we proposed a open-vocabulary panoptic system based on neural fields for scene understanding. Our method implicitly reconstructs the scene geometry from 2D images and simultaneously gains panoptic informaiton from 2D proposals computed by off-the-shelf 2D networks.

**Abstract**

&nbsp;&nbsp;&nbsp;&nbsp;<i>"Recently, methods have been proposed for 3D open- vocabulary semantic segmentation. Such methods are able to segment scenes into arbitrary classes based on text descriptions provided during runtime. In this paper, we propose to the best of our knowledge the first algorithm for open-vocabulary panoptic segmentation in 3D scenes. Our algorithm, Panoptic Vision- Language Feature Fields (PVLFF), learns a semantic feature field of the scene by distilling vision-language features from a pretrained 2D model, and jointly fits an instance feature field through contrastive learning using 2D instance segments on input frames. Despite not being trained on the target classes, our method achieves panoptic segmentation performance similar to the state-of-the-art closed-set 3D systems on the HyperSim, Scan- Net and Replica dataset and additionally outperforms current 3D open-vocabulary systems in terms of semantic segmentation. We ablate the components of our method to demonstrate the effectiveness of our model architecture. Our code will be available at [https://github.com/ethz-asl/pvlff](https://github.com/ethz-asl/pvlff)."</i>

<iframe width="560" height="315" src="https://www.youtube.com/embed/mZoujkg_axE?si=-dIba18kIHz6aXF0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>

### Main Contributions
* A hierarchical instance feature field that enables obtaining 3D instance segments from 2D proposals using contrastive learning;
* To the best of our knowledge, the first zero-shot open-vocabulary panoptic segmentation system.

### Overview of PVLFF
![Overview of PVLFF]({{ base_path }}/images/publication/PVLFF/teaser.png)

### Some visual results
![Visual Results]({{ base_path }}/images/publication/PVLFF/visual_results.jpg)

Please find more visualization results on our [website](https://ethz-asl.github.io/pvlff/) and check more details in the [paper](https://arxiv.org/abs/2309.05448).